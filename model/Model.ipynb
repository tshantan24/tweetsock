{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, Embedding, CuDNNLSTM, Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Party</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Gov. @ricardorossello's comments degrading wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Looks like Trump will end his discriminatory c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>For several years we sought to replace our sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Proud to announce that @fema awarded @PolkCoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>STURDY Bill passed @EnergyCommerce Cmte today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Enough is enough! Billionaire super predator J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>We continue our efforts to provide American Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>We're committed to defending quality &amp;amp; aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Robocalls aren’t just annoying. Many are outri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>This is why we continue to fight @jediabetical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Handle     Party                                              Tweet\n",
       "0  RepDarrenSoto  Democrat  Gov. @ricardorossello's comments degrading wom...\n",
       "1  RepDarrenSoto  Democrat  Looks like Trump will end his discriminatory c...\n",
       "2  RepDarrenSoto  Democrat  For several years we sought to replace our sta...\n",
       "3  RepDarrenSoto  Democrat  Proud to announce that @fema awarded @PolkCoun...\n",
       "4  RepDarrenSoto  Democrat  STURDY Bill passed @EnergyCommerce Cmte today ...\n",
       "5  RepDarrenSoto  Democrat  Enough is enough! Billionaire super predator J...\n",
       "6  RepDarrenSoto  Democrat  We continue our efforts to provide American Ci...\n",
       "7  RepDarrenSoto  Democrat  We're committed to defending quality &amp; aff...\n",
       "8  RepDarrenSoto  Democrat  Robocalls aren’t just annoying. Many are outri...\n",
       "9  RepDarrenSoto  Democrat  This is why we continue to fight @jediabetical..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Party</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>0</td>\n",
       "      <td>Gov. @ricardorossello's comments degrading wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>0</td>\n",
       "      <td>Looks like Trump will end his discriminatory c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>0</td>\n",
       "      <td>For several years we sought to replace our sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>0</td>\n",
       "      <td>Proud to announce that @fema awarded @PolkCoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>0</td>\n",
       "      <td>STURDY Bill passed @EnergyCommerce Cmte today ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Handle  Party                                              Tweet\n",
       "0  RepDarrenSoto      0  Gov. @ricardorossello's comments degrading wom...\n",
       "1  RepDarrenSoto      0  Looks like Trump will end his discriminatory c...\n",
       "2  RepDarrenSoto      0  For several years we sought to replace our sta...\n",
       "3  RepDarrenSoto      0  Proud to announce that @fema awarded @PolkCoun...\n",
       "4  RepDarrenSoto      0  STURDY Bill passed @EnergyCommerce Cmte today ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Party'] = pd.Categorical(df.Party)\n",
    "df['Party'] = pd.get_dummies(df['Party'], drop_first=True)\n",
    "# df[df['Party'] == 0]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>0</b> - Democrat <br>\n",
    "<b>1</b> - Republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000,)\n",
      "(90000,)\n"
     ]
    }
   ],
   "source": [
    "X = df['Tweet']\n",
    "Y = df['Party']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gov. @ricardorossello's comments degrading women, including my dear friend @MMViverito, are unacceptable. I condemn these demeaning words. Now more than ever, Puerto Rico is in need of strong leadership. I urge the Governor to use appropriate language &amp; always respect women.\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.str.replace('&amp;', \"and\")\n",
    "X = X.str.replace('\\xa0', \" \")\n",
    "X = X.str.replace('\\u2003', \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We’re indeed in a constitutional crisis and must defend our democracy! AG Barr should be held in contempt for refusal to testify and submit docs. As co-equal branch, Congress has a constitutional obligation to oversight, combat corruption and get to the truth!\n",
      "https://t.co/vjZ2P7PSWl\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[122])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_link(sent):\n",
    "    sent = str(sent)\n",
    "    return sent[:sent.find(\"https://\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(remove_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We’re indeed in a constitutional crisis and must defend our democracy! AG Barr should be held in contempt for refusal to testify and submit docs. As co-equal branch, Congress has a constitutional obligation to oversight, combat corruption and get to the truth!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[122])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuations and converting sentences into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "punctuation = punctuation + \"—\\n\\t\"\n",
    "regex = re.compile('[%s]' % re.escape(punctuation))\n",
    "\n",
    "def remove_punctuations(sentence):\n",
    "    return regex.sub('', sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(remove_punctuations)\n",
    "X = X.apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we’re indeed in a constitutional crisis and must defend our democracy ag barr should be held in contempt for refusal to testify and submit docs as coequal branch congress has a constitutional obligation to oversight combat corruption and get to the truth\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what we saw today was horrifying that’s why we need to continue to shine a light on what’s happening at our southern border  we have to make sure that when congress allocates funding there are oversight provisions msnbc allinwithchris '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "89970    0\n",
       "89971    0\n",
       "89972    0\n",
       "89973    0\n",
       "89974    0\n",
       "89975    0\n",
       "89976    0\n",
       "89977    0\n",
       "89978    0\n",
       "89979    0\n",
       "89980    0\n",
       "89981    0\n",
       "89982    0\n",
       "89983    0\n",
       "89984    0\n",
       "89985    0\n",
       "89986    0\n",
       "89987    0\n",
       "89988    0\n",
       "89989    0\n",
       "89990    0\n",
       "89991    0\n",
       "89992    0\n",
       "89993    0\n",
       "89994    0\n",
       "89995    0\n",
       "89996    0\n",
       "89997    0\n",
       "89998    0\n",
       "89999    0\n",
       "Name: Party, Length: 89541, dtype: uint8"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = list(X[X==\"\"].index)\n",
    "x = X.drop(ind)\n",
    "y = Y.drop(ind)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "<b><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tokenizer and creating a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer(oov_token=\"UNK\")\n",
    "a = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of a: 89541\n"
     ]
    }
   ],
   "source": [
    "print(\"Len of a: {}\".format(len(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 89911\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "print(\"Vocabulary size: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 74\n"
     ]
    }
   ],
   "source": [
    "max_sent_len = len(max(X, key=len).split()) + 1\n",
    "print(\"Maximum sentence length: {}\".format(max_sent_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentences(sentence, word_to_index):\n",
    "    encoded = np.zeros((1, max_sent_len))\n",
    "    sentence_words = sentence.lower().split()\n",
    "    j = 0\n",
    "    for w in sentence_words:\n",
    "        encoded[0, j] = word_to_index[w]\n",
    "        j += 1\n",
    "    \n",
    "    return np.float32(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_X_train = t.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  99,   93, 1529, ...,    0,    0,    0],\n",
       "       [   2,  839,   10, ...,    0,    0,    0],\n",
       "       [1126, 1192, 5953, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,   41,  271, ...,    0,    0,    0],\n",
       "       [  26,   10, 2651, ...,    0,    0,    0],\n",
       "       [ 128,   13,  590, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_train = pad_sequences(encoded_X_train, maxlen=max_sent_len, padding='post')\n",
    "padded_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim, input_length=max_sent_len, trainable=False)\n",
    "trained_embedding_layer = Embedding(input_dim=vocab_size, output_dim=emb_dim, input_length=max_sent_len, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoded_X_train1 = tf.convert_to_tensor(encoded_X_train, np.float32)\n",
    "layer_1 = embedding_layer(padded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_layer_1 = trained_embedding_layer(padded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "learning_rate = 0.05\n",
    "epochs = 50\n",
    "num_hidden_units = 128\n",
    "timesteps = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 00:53:54.259601 20456 deprecation.py:506] From C:\\Users\\tshan\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0718 00:53:54.263591 20456 deprecation.py:506] From C:\\Users\\tshan\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0718 00:53:54.264588 20456 deprecation.py:506] From C:\\Users\\tshan\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0718 00:53:54.265586 20456 deprecation.py:506] From C:\\Users\\tshan\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    Bidirectional(CuDNNLSTM(128, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    CuDNNLSTM(128),\n",
    "    Dropout(0.5),\n",
    "    Dense(2),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 74, 50)            4495550   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 74, 256)           184320    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 74, 256)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               197632    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,877,760\n",
      "Trainable params: 382,210\n",
      "Non-trainable params: 4,495,550\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71632/71632 [==============================] - 29s 398us/sample - loss: 0.6933 - acc: 0.4984\n",
      "Epoch 2/50\n",
      "71632/71632 [==============================] - 28s 398us/sample - loss: 0.6932 - acc: 0.5016\n",
      "Epoch 3/50\n",
      "71632/71632 [==============================] - 35s 489us/sample - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 4/50\n",
      "71632/71632 [==============================] - 35s 483us/sample - loss: 0.6931 - acc: 0.5029\n",
      "Epoch 5/50\n",
      "71632/71632 [==============================] - 31s 435us/sample - loss: 0.6932 - acc: 0.4982\n",
      "Epoch 6/50\n",
      "71632/71632 [==============================] - 32s 446us/sample - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 7/50\n",
      "71632/71632 [==============================] - 39s 545us/sample - loss: 0.6932 - acc: 0.5007\n",
      "Epoch 8/50\n",
      "71632/71632 [==============================] - 33s 466us/sample - loss: 0.6932 - acc: 0.4970\n",
      "Epoch 9/50\n",
      "71632/71632 [==============================] - 34s 475us/sample - loss: 0.6932 - acc: 0.5004\n",
      "Epoch 10/50\n",
      "71632/71632 [==============================] - 35s 492us/sample - loss: 0.6932 - acc: 0.5016 - loss: 0.6932 - acc: 0.50\n",
      "Epoch 11/50\n",
      "71632/71632 [==============================] - 34s 468us/sample - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 12/50\n",
      "71632/71632 [==============================] - 42s 590us/sample - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 13/50\n",
      "71632/71632 [==============================] - 37s 520us/sample - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 14/50\n",
      "71632/71632 [==============================] - 38s 524us/sample - loss: 0.6931 - acc: 0.5013\n",
      "Epoch 15/50\n",
      "71632/71632 [==============================] - 38s 530us/sample - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 16/50\n",
      "71632/71632 [==============================] - 37s 512us/sample - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 17/50\n",
      "71632/71632 [==============================] - 49s 687us/sample - loss: 0.6932 - acc: 0.4997\n",
      "Epoch 18/50\n",
      "71632/71632 [==============================] - 39s 546us/sample - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 19/50\n",
      "71632/71632 [==============================] - 18s 256us/sample - loss: 0.6931 - acc: 0.4996\n",
      "Epoch 20/50\n",
      "71632/71632 [==============================] - 16s 225us/sample - loss: 0.6932 - acc: 0.4993\n",
      "Epoch 21/50\n",
      "71632/71632 [==============================] - 19s 260us/sample - loss: 0.6931 - acc: 0.5010\n",
      "Epoch 22/50\n",
      "71632/71632 [==============================] - 18s 251us/sample - loss: 0.6932 - acc: 0.4997\n",
      "Epoch 23/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.5008\n",
      "Epoch 24/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5011\n",
      "Epoch 25/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 26/50\n",
      "71632/71632 [==============================] - 18s 247us/sample - loss: 0.6931 - acc: 0.5011\n",
      "Epoch 27/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4961\n",
      "Epoch 28/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4998\n",
      "Epoch 29/50\n",
      "71632/71632 [==============================] - 17s 244us/sample - loss: 0.6932 - acc: 0.4994\n",
      "Epoch 30/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 32/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 33/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5024\n",
      "Epoch 34/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5007\n",
      "Epoch 35/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 36/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5012\n",
      "Epoch 37/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.5002 - loss: 0.6932 -\n",
      "Epoch 38/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5002\n",
      "Epoch 39/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4988\n",
      "Epoch 40/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5021\n",
      "Epoch 41/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.4981\n",
      "Epoch 42/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 43/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5005\n",
      "Epoch 44/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5005\n",
      "Epoch 45/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4987 - loss: 0.6932 - acc: 0.49\n",
      "Epoch 46/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.4976\n",
      "Epoch 47/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4993\n",
      "Epoch 48/50\n",
      "71632/71632 [==============================] - 18s 245us/sample - loss: 0.6932 - acc: 0.5031\n",
      "Epoch 49/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.4986\n",
      "Epoch 50/50\n",
      "71632/71632 [==============================] - 18s 246us/sample - loss: 0.6932 - acc: 0.5004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9009e8cc0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_X_train, y_train, epochs=50, batch_size = 400, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    embedding_layer,\n",
    "    Bidirectional(CuDNNLSTM(128, return_sequences=False)),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71632/71632 [==============================] - 5s 77us/sample - loss: 0.6890 - acc: 0.5358\n",
      "Epoch 2/100\n",
      "71632/71632 [==============================] - 5s 70us/sample - loss: 0.6865 - acc: 0.5494\n",
      "Epoch 3/100\n",
      "71632/71632 [==============================] - 5s 72us/sample - loss: 0.6833 - acc: 0.5588\n",
      "Epoch 4/100\n",
      "71632/71632 [==============================] - 5s 73us/sample - loss: 0.6809 - acc: 0.56540s - loss: 0.6809 - acc: 0\n",
      "Epoch 5/100\n",
      "71632/71632 [==============================] - 6s 82us/sample - loss: 0.6802 - acc: 0.5651\n",
      "Epoch 6/100\n",
      "71632/71632 [==============================] - 6s 82us/sample - loss: 0.6782 - acc: 0.5712\n",
      "Epoch 7/100\n",
      "71632/71632 [==============================] - 6s 83us/sample - loss: 0.6780 - acc: 0.5690\n",
      "Epoch 8/100\n",
      "71632/71632 [==============================] - 6s 82us/sample - loss: 0.6763 - acc: 0.5723\n",
      "Epoch 9/100\n",
      "71632/71632 [==============================] - 6s 83us/sample - loss: 0.6756 - acc: 0.5742\n",
      "Epoch 10/100\n",
      "71632/71632 [==============================] - 6s 82us/sample - loss: 0.6752 - acc: 0.5739\n",
      "Epoch 11/100\n",
      "71632/71632 [==============================] - 7s 98us/sample - loss: 0.6743 - acc: 0.5769\n",
      "Epoch 12/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.6742 - acc: 0.5756\n",
      "Epoch 13/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6737 - acc: 0.5766\n",
      "Epoch 14/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6736 - acc: 0.5776\n",
      "Epoch 15/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6734 - acc: 0.5786\n",
      "Epoch 16/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6721 - acc: 0.5801\n",
      "Epoch 17/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6711 - acc: 0.5832\n",
      "Epoch 18/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6713 - acc: 0.5817\n",
      "Epoch 19/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6707 - acc: 0.5819\n",
      "Epoch 20/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6705 - acc: 0.5825\n",
      "Epoch 21/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6700 - acc: 0.5821\n",
      "Epoch 22/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6687 - acc: 0.5863\n",
      "Epoch 23/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6680 - acc: 0.5861\n",
      "Epoch 24/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6681 - acc: 0.5865\n",
      "Epoch 25/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6664 - acc: 0.5885\n",
      "Epoch 26/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6655 - acc: 0.5913\n",
      "Epoch 27/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6642 - acc: 0.5932\n",
      "Epoch 28/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6621 - acc: 0.5949\n",
      "Epoch 29/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6585 - acc: 0.5988\n",
      "Epoch 30/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6575 - acc: 0.6020\n",
      "Epoch 31/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6552 - acc: 0.6041\n",
      "Epoch 32/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6527 - acc: 0.6068\n",
      "Epoch 33/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6511 - acc: 0.6076\n",
      "Epoch 34/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6486 - acc: 0.6108\n",
      "Epoch 35/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6473 - acc: 0.6122\n",
      "Epoch 36/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6467 - acc: 0.6141\n",
      "Epoch 37/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6442 - acc: 0.6172\n",
      "Epoch 38/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6411 - acc: 0.6219\n",
      "Epoch 39/100\n",
      "71632/71632 [==============================] - 8s 105us/sample - loss: 0.6382 - acc: 0.6259\n",
      "Epoch 40/100\n",
      "71632/71632 [==============================] - 8s 118us/sample - loss: 0.6372 - acc: 0.6254\n",
      "Epoch 41/100\n",
      "71632/71632 [==============================] - 8s 117us/sample - loss: 0.6358 - acc: 0.6274\n",
      "Epoch 42/100\n",
      "71632/71632 [==============================] - 8s 117us/sample - loss: 0.6338 - acc: 0.6300\n",
      "Epoch 43/100\n",
      "71632/71632 [==============================] - 8s 117us/sample - loss: 0.6298 - acc: 0.6355\n",
      "Epoch 44/100\n",
      "71632/71632 [==============================] - 8s 117us/sample - loss: 0.6298 - acc: 0.6333\n",
      "Epoch 45/100\n",
      "71632/71632 [==============================] - 7s 99us/sample - loss: 0.6271 - acc: 0.6381\n",
      "Epoch 46/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6236 - acc: 0.6419\n",
      "Epoch 47/100\n",
      "71632/71632 [==============================] - 7s 99us/sample - loss: 0.6215 - acc: 0.6422\n",
      "Epoch 48/100\n",
      "71632/71632 [==============================] - 7s 96us/sample - loss: 0.6213 - acc: 0.6431\n",
      "Epoch 49/100\n",
      "71632/71632 [==============================] - 8s 116us/sample - loss: 0.6170 - acc: 0.6485\n",
      "Epoch 50/100\n",
      "71632/71632 [==============================] - 9s 123us/sample - loss: 0.6144 - acc: 0.6522s - loss: 0.6144 - acc: 0.652\n",
      "Epoch 51/100\n",
      "71632/71632 [==============================] - 8s 106us/sample - loss: 0.6121 - acc: 0.6532\n",
      "Epoch 52/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6108 - acc: 0.6510\n",
      "Epoch 53/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6079 - acc: 0.6566\n",
      "Epoch 54/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.6058 - acc: 0.6577\n",
      "Epoch 55/100\n",
      "71632/71632 [==============================] - 8s 106us/sample - loss: 0.6027 - acc: 0.6594\n",
      "Epoch 56/100\n",
      "71632/71632 [==============================] - 9s 127us/sample - loss: 0.6004 - acc: 0.6641\n",
      "Epoch 57/100\n",
      "71632/71632 [==============================] - 9s 126us/sample - loss: 0.5957 - acc: 0.6670\n",
      "Epoch 58/100\n",
      "71632/71632 [==============================] - 9s 126us/sample - loss: 0.5945 - acc: 0.6679\n",
      "Epoch 59/100\n",
      "71632/71632 [==============================] - 8s 106us/sample - loss: 0.5936 - acc: 0.6715\n",
      "Epoch 60/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5895 - acc: 0.6739\n",
      "Epoch 61/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5865 - acc: 0.6756\n",
      "Epoch 62/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5841 - acc: 0.6790\n",
      "Epoch 63/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5804 - acc: 0.6811\n",
      "Epoch 64/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5784 - acc: 0.6812\n",
      "Epoch 65/100\n",
      "71632/71632 [==============================] - 8s 112us/sample - loss: 0.5740 - acc: 0.6867\n",
      "Epoch 66/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5749 - acc: 0.6867\n",
      "Epoch 67/100\n",
      "71632/71632 [==============================] - 8s 116us/sample - loss: 0.5694 - acc: 0.6899\n",
      "Epoch 68/100\n",
      "71632/71632 [==============================] - 8s 116us/sample - loss: 0.5669 - acc: 0.6922\n",
      "Epoch 69/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5635 - acc: 0.6949\n",
      "Epoch 70/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5597 - acc: 0.6980\n",
      "Epoch 71/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5594 - acc: 0.6988\n",
      "Epoch 72/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5556 - acc: 0.7007\n",
      "Epoch 73/100\n",
      "71632/71632 [==============================] - 8s 114us/sample - loss: 0.5594 - acc: 0.7000\n",
      "Epoch 74/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5529 - acc: 0.7043\n",
      "Epoch 75/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5446 - acc: 0.7097s - loss: 0.5448 - acc: 0.7\n",
      "Epoch 76/100\n",
      "71632/71632 [==============================] - 8s 114us/sample - loss: 0.5409 - acc: 0.7119s - l\n",
      "Epoch 77/100\n",
      "71632/71632 [==============================] - 8s 115us/sample - loss: 0.5401 - acc: 0.7137\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71632/71632 [==============================] - 8s 114us/sample - loss: 0.5360 - acc: 0.7164\n",
      "Epoch 79/100\n",
      "71632/71632 [==============================] - 7s 95us/sample - loss: 0.5306 - acc: 0.7204\n",
      "Epoch 80/100\n",
      "71632/71632 [==============================] - 6s 90us/sample - loss: 0.5288 - acc: 0.7210\n",
      "Epoch 81/100\n",
      "71632/71632 [==============================] - 6s 91us/sample - loss: 0.5238 - acc: 0.7253\n",
      "Epoch 82/100\n",
      "71632/71632 [==============================] - 9s 128us/sample - loss: 0.5182 - acc: 0.7281\n",
      "Epoch 83/100\n",
      "71632/71632 [==============================] - 8s 117us/sample - loss: 0.5156 - acc: 0.7311\n",
      "Epoch 84/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5187 - acc: 0.7283\n",
      "Epoch 85/100\n",
      "71632/71632 [==============================] - 7s 99us/sample - loss: 0.5139 - acc: 0.7326\n",
      "Epoch 86/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5074 - acc: 0.7360\n",
      "Epoch 87/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5038 - acc: 0.7382\n",
      "Epoch 88/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.5068 - acc: 0.7361\n",
      "Epoch 89/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4972 - acc: 0.7433\n",
      "Epoch 90/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4932 - acc: 0.7455\n",
      "Epoch 91/100\n",
      "71632/71632 [==============================] - 7s 101us/sample - loss: 0.4889 - acc: 0.7503\n",
      "Epoch 92/100\n",
      "71632/71632 [==============================] - 9s 125us/sample - loss: 0.4893 - acc: 0.7492\n",
      "Epoch 93/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4834 - acc: 0.7549\n",
      "Epoch 94/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4804 - acc: 0.7546\n",
      "Epoch 95/100\n",
      "71632/71632 [==============================] - 9s 127us/sample - loss: 0.4754 - acc: 0.7593\n",
      "Epoch 96/100\n",
      "71632/71632 [==============================] - 7s 91us/sample - loss: 0.4833 - acc: 0.7538\n",
      "Epoch 97/100\n",
      "71632/71632 [==============================] - 9s 119us/sample - loss: 0.4689 - acc: 0.7618\n",
      "Epoch 98/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4671 - acc: 0.7648\n",
      "Epoch 99/100\n",
      "71632/71632 [==============================] - 7s 100us/sample - loss: 0.4667 - acc: 0.7647\n",
      "Epoch 100/100\n",
      "71632/71632 [==============================] - 9s 121us/sample - loss: 0.4617 - acc: 0.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a910a4a1d0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(padded_X_train, y_train, epochs=100, batch_size = 400, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71632/71632 [==============================] - 11s 160us/sample - loss: 0.6892 - acc: 0.5384\n",
      "Epoch 2/150\n",
      "71632/71632 [==============================] - 11s 155us/sample - loss: 0.6859 - acc: 0.5510 - loss: 0.6860 - acc:\n",
      "Epoch 3/150\n",
      "71632/71632 [==============================] - 11s 155us/sample - loss: 0.6825 - acc: 0.5606\n",
      "Epoch 4/150\n",
      "71632/71632 [==============================] - 11s 156us/sample - loss: 0.6812 - acc: 0.5657\n",
      "Epoch 5/150\n",
      "71632/71632 [==============================] - 11s 157us/sample - loss: 0.6798 - acc: 0.5664 - loss: 0.6799 - acc:\n",
      "Epoch 6/150\n",
      "71632/71632 [==============================] - 11s 157us/sample - loss: 0.6783 - acc: 0.5686 - loss: 0.6782 - acc\n",
      "Epoch 7/150\n",
      "71632/71632 [==============================] - 11s 158us/sample - loss: 0.6776 - acc: 0.5690\n",
      "Epoch 8/150\n",
      "71632/71632 [==============================] - 11s 158us/sample - loss: 0.6807 - acc: 0.5608\n",
      "Epoch 9/150\n",
      "71632/71632 [==============================] - 11s 159us/sample - loss: 0.6776 - acc: 0.5704\n",
      "Epoch 10/150\n",
      "71632/71632 [==============================] - 11s 159us/sample - loss: 0.6761 - acc: 0.5746\n",
      "Epoch 11/150\n",
      "71632/71632 [==============================] - 11s 159us/sample - loss: 0.6758 - acc: 0.5715\n",
      "Epoch 12/150\n",
      "71632/71632 [==============================] - 11s 159us/sample - loss: 0.6752 - acc: 0.5753\n",
      "Epoch 13/150\n",
      "71632/71632 [==============================] - 12s 168us/sample - loss: 0.6744 - acc: 0.5749\n",
      "Epoch 14/150\n",
      "71632/71632 [==============================] - 12s 172us/sample - loss: 0.6740 - acc: 0.5775\n",
      "Epoch 15/150\n",
      "71632/71632 [==============================] - 12s 171us/sample - loss: 0.6736 - acc: 0.5773\n",
      "Epoch 16/150\n",
      "71632/71632 [==============================] - 12s 171us/sample - loss: 0.6735 - acc: 0.5774\n",
      "Epoch 17/150\n",
      "71632/71632 [==============================] - 13s 181us/sample - loss: 0.6727 - acc: 0.5786\n",
      "Epoch 18/150\n",
      "71632/71632 [==============================] - 13s 182us/sample - loss: 0.6725 - acc: 0.5782\n",
      "Epoch 19/150\n",
      "71632/71632 [==============================] - 15s 209us/sample - loss: 0.6721 - acc: 0.5803\n",
      "Epoch 20/150\n",
      "71632/71632 [==============================] - 15s 208us/sample - loss: 0.6711 - acc: 0.5806\n",
      "Epoch 21/150\n",
      "71632/71632 [==============================] - 15s 208us/sample - loss: 0.6703 - acc: 0.5826\n",
      "Epoch 22/150\n",
      "71632/71632 [==============================] - 15s 208us/sample - loss: 0.6703 - acc: 0.5835\n",
      "Epoch 23/150\n",
      "71632/71632 [==============================] - 15s 209us/sample - loss: 0.6691 - acc: 0.5828\n",
      "Epoch 24/150\n",
      "71632/71632 [==============================] - 15s 209us/sample - loss: 0.6678 - acc: 0.5858\n",
      "Epoch 25/150\n",
      "71632/71632 [==============================] - 15s 209us/sample - loss: 0.6664 - acc: 0.5882\n",
      "Epoch 26/150\n",
      "71632/71632 [==============================] - 20s 273us/sample - loss: 0.6640 - acc: 0.5924\n",
      "Epoch 27/150\n",
      "71632/71632 [==============================] - 15s 213us/sample - loss: 0.6620 - acc: 0.5931\n",
      "Epoch 28/150\n",
      "71632/71632 [==============================] - 17s 240us/sample - loss: 0.6583 - acc: 0.5981\n",
      "Epoch 29/150\n",
      "71632/71632 [==============================] - 16s 230us/sample - loss: 0.6579 - acc: 0.5980 - loss: 0.6577 - acc: 0\n",
      "Epoch 30/150\n",
      "71632/71632 [==============================] - 17s 231us/sample - loss: 0.6563 - acc: 0.6005\n",
      "Epoch 31/150\n",
      "71632/71632 [==============================] - 17s 231us/sample - loss: 0.6539 - acc: 0.6047\n",
      "Epoch 32/150\n",
      "71632/71632 [==============================] - 18s 247us/sample - loss: 0.6514 - acc: 0.6084\n",
      "Epoch 33/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6491 - acc: 0.6123\n",
      "Epoch 34/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6473 - acc: 0.6128\n",
      "Epoch 35/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6490 - acc: 0.6112\n",
      "Epoch 36/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6432 - acc: 0.6187\n",
      "Epoch 37/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6403 - acc: 0.6219\n",
      "Epoch 38/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6619 - acc: 0.6082\n",
      "Epoch 39/150\n",
      "71632/71632 [==============================] - 18s 250us/sample - loss: 0.6416 - acc: 0.6222\n",
      "Epoch 40/150\n",
      "71632/71632 [==============================] - 18s 251us/sample - loss: 0.6372 - acc: 0.6249\n",
      "Epoch 41/150\n",
      "71632/71632 [==============================] - 22s 301us/sample - loss: 0.6356 - acc: 0.6282\n",
      "Epoch 42/150\n",
      "35200/71632 [=============>................] - ETA: 10s - loss: 0.6310 - acc: 0.6309"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    embedding_layer,\n",
    "    Bidirectional(CuDNNLSTM(256, return_sequences=False)),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(padded_X_train, y_train, epochs=150, batch_size = 400, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def weight_variable(shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W',\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b',\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def BiRNN(x, weights, biases, timesteps, num_hidden):\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get BiRNN cell output\n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights) + biases"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
